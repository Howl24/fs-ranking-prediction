{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from pathlib import Path\n",
    "# pd.set_option('display.max_columns', 1000)\n",
    "# pd.set_option('display.max_rows', 400)\n",
    "sns.set()\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from project.ranker.ranker import RankingPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 39) (60, 13) (60, 13)\n",
      "CPU times: user 45 s, sys: 5.07 s, total: 50.1 s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "rp = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('estimator', RankingPredictor(\"ma_100\", n_neighbors=15)),\n",
    "])\n",
    "df_mf, df_rank, df_scores = rp.named_steps['estimator'].get_data()\n",
    "\n",
    "X, _, y, _, y_scores, _ = train_test_split(df_mf.values,\n",
    "                                           df_rank.values,\n",
    "                                           df_scores.values,\n",
    "                                           test_size=0,\n",
    "                                           random_state=42)\n",
    "print(X.shape, y.shape, y_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class RankDataset(Dataset):\n",
    "    def __init__(self, X, y, y_scores):\n",
    "        super().__init__()\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.int64)\n",
    "        self.y_scores = y_scores.astype(np.float32)\n",
    "        \n",
    "        self.mf_sz = X.shape[1]\n",
    "        self.fs_sz = y.shape[1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx], self.y_scores[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide2long(X, y):\n",
    "    n_samples, n_classes = y.shape\n",
    "    X_cont = np.repeat(X, n_classes, axis=0)\n",
    "    X_cats = np.array(list(range(n_classes)) * n_samples)\n",
    "    return X_cont, X_cats.astype(int), y.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from project.ranker.neural_ranker import RankNet\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, mf_sz, fs_sz, params):\n",
    "        self.mf_sz, self.fs_sz = mf_sz, fs_sz\n",
    "        self.latent_sz = params['latent_sz']\n",
    "        self.epochs = params['epochs']\n",
    "        self.lr = params['learning_rate']\n",
    "        self.num_negative_samples = params['num_negative_samples']\n",
    "        \n",
    "        self.model = RankNet(mf_sz, fs_sz, self.latent_sz)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "    def train(self, dl):\n",
    "        train_losses = []\n",
    "        for epoch in range(self.epochs):\n",
    "            train_loss = 0\n",
    "            for X, y, y_scores in dl:\n",
    "                # for each dataset\n",
    "                X_cont, X_cats, y_long = wide2long(X, y)\n",
    "                X_cats = torch.LongTensor(X_cats)\n",
    "\n",
    "                positive_pred = self.model(X_cont, X_cats)\n",
    "                negative_pred = self.get_multiple_negative_preds(X_cont, n=self.num_negative_samples)\n",
    "                \n",
    "                train_loss += self.train_step(positive_pred, negative_pred)\n",
    "\n",
    "            train_losses.append(train_loss) \n",
    "        return train_losses\n",
    "    \n",
    "    def get_negative_preds(self, X_cont):\n",
    "        negative_items = np.random.randint(0, self.fs_sz, len(X_cont), dtype=np.int64)\n",
    "        X_cats = torch.from_numpy(negative_items)\n",
    "        return self.model(X_cont, X_cats)\n",
    "    \n",
    "    def get_multiple_negative_preds(self, X_cont, n=10):\n",
    "        negative_preds = self.get_negative_preds(X_cont[None, ...] \n",
    "                                                 .expand(n, *X_cont.shape)\n",
    "                                                 .reshape(-1, X_cont.shape[-1]))\n",
    "        return negative_preds.view(n, len(X_cont))\n",
    "    \n",
    "    def train_step(self, positive_preds, negative_preds):\n",
    "        self.model.train()\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        highest_negative_preds, _ = torch.max(negative_preds, 0)\n",
    "        loss = torch.clamp(highest_negative_preds - positive_preds + 1.0, 0.0).mean()\n",
    "        \n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "    \n",
    "    def predict(self, dl):\n",
    "        preds = []\n",
    "        self.model.eval()\n",
    "        for X, y, y_scores in dl:\n",
    "            X_cont, X_cats, y_long = wide2long(X, y)\n",
    "            X_cats = torch.LongTensor(X_cats)\n",
    "            X_cont.requires_grad_(False)\n",
    "            X_cats.requires_grad_(False)\n",
    "            \n",
    "            pred = self.model(X_cont, X_cats).cpu().detach().numpy()\n",
    "            \n",
    "            pred = np.array([rankdata(x, method='ordinal') for x in \\\n",
    "                             np.reshape(pred, y.shape)]).astype(int)\n",
    "            preds.extend(pred)\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.utils.metrics import evaluate_metric\n",
    "\n",
    "def cv_neuralnet(X, y, y_scores, kfolds, params, verbose_folds=False):\n",
    "    results = []\n",
    "    models = []\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    for idx, (trn_idx, val_idx) in enumerate(kfolds.split(X, y)):\n",
    "        X_trn, y_trn, y_scores_trn = X[trn_idx], y[trn_idx], y_scores[trn_idx]\n",
    "        X_val, y_val, y_scores_val = X[val_idx], y[val_idx], y_scores[val_idx]\n",
    "        \n",
    "        trn_ds = RankDataset(X_trn, y_trn, y_scores_trn)\n",
    "        val_ds = RankDataset(X_val, y_val, y_scores_val)\n",
    "        \n",
    "        neuralnet = NeuralNetwork(trn_ds.mf_sz, trn_ds.fs_sz, params)\n",
    "        trn_dl = DataLoader(trn_ds, batch_size=params['batch_sz'], shuffle=True)\n",
    "        neuralnet.train(trn_dl)\n",
    "        \n",
    "        trn_dl = DataLoader(trn_ds, batch_size=params['batch_sz'], shuffle=False)\n",
    "        val_dl = DataLoader(val_ds, batch_size=params['batch_sz'], shuffle=False)\n",
    "        \n",
    "        y_pred_trn = neuralnet.predict(trn_dl)\n",
    "        y_pred_val = neuralnet.predict(val_dl)\n",
    "        \n",
    "        trn_spearman = evaluate_metric(\"spearman\", y_trn, y_pred_trn)\n",
    "        trn_acc_loss = evaluate_metric(\"mean_acc_loss\", y_scores_trn, y_pred_trn)\n",
    "        val_spearman = evaluate_metric(\"spearman\", y_val, y_pred_val)\n",
    "        val_acc_loss = evaluate_metric(\"mean_acc_loss\", y_scores_val, y_pred_val)\n",
    "        \n",
    "        if verbose_folds:\n",
    "            print(f'Fold {idx + 1:>3} | '\n",
    "                  f'Trn_Spearman: {trn_spearman: .4f} | '\n",
    "                  f'Val_Spearman: {val_spearman: .4f} | '\n",
    "                  f'Trn_ACCLoss: {trn_acc_loss: .4f} | '\n",
    "                  f'Val_ACCLoss: {val_acc_loss: .4f}')\n",
    "            \n",
    "        results.append((trn_spearman, val_spearman, \n",
    "                        trn_acc_loss, val_acc_loss))\n",
    "        models.append(neuralnet)\n",
    "        \n",
    "#         break # 1-fold\n",
    "          \n",
    "    results = np.array(results)\n",
    "    print()\n",
    "    print(f'Trn_Spearman: {results[:,0].mean(): .4f} +/-{results[:,0].std():.4f} | '\n",
    "          f'Val_Spearman: {results[:,1].mean(): .4f} +/-{results[:,1].std():.4f}\\n'\n",
    "          f'Trn_ACCLoss:  {results[:,2].mean(): .4f} +/-{results[:,2].std():.4f} | '\n",
    "          f'Val_ACCLoss:  {results[:,3].mean(): .4f} +/-{results[:,3].std():.4f}')\n",
    "    print()\n",
    "    return results, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold   1 | Trn_Spearman:  0.0451 | Val_Spearman: -0.0128 | Trn_ACCLoss:  0.1146 | Val_ACCLoss:  0.1505\n",
      "Fold   2 | Trn_Spearman: -0.0223 | Val_Spearman:  0.0147 | Trn_ACCLoss:  0.1271 | Val_ACCLoss:  0.2006\n",
      "Fold   3 | Trn_Spearman:  0.0256 | Val_Spearman: -0.0485 | Trn_ACCLoss:  0.1427 | Val_ACCLoss:  0.0413\n",
      "Fold   4 | Trn_Spearman:  0.0052 | Val_Spearman: -0.0778 | Trn_ACCLoss:  0.1516 | Val_ACCLoss:  0.2452\n",
      "Fold   5 | Trn_Spearman: -0.0134 | Val_Spearman: -0.0760 | Trn_ACCLoss:  0.1548 | Val_ACCLoss:  0.0621\n",
      "Fold   6 | Trn_Spearman:  0.0038 | Val_Spearman: -0.0055 | Trn_ACCLoss:  0.1330 | Val_ACCLoss:  0.2291\n",
      "Fold   7 | Trn_Spearman: -0.0151 | Val_Spearman:  0.0998 | Trn_ACCLoss:  0.1205 | Val_ACCLoss:  0.0958\n",
      "Fold   8 | Trn_Spearman:  0.0119 | Val_Spearman: -0.0275 | Trn_ACCLoss:  0.1504 | Val_ACCLoss:  0.0493\n",
      "Fold   9 | Trn_Spearman:  0.0041 | Val_Spearman: -0.1685 | Trn_ACCLoss:  0.1111 | Val_ACCLoss:  0.1847\n",
      "Fold  10 | Trn_Spearman:  0.0629 | Val_Spearman:  0.0559 | Trn_ACCLoss:  0.1334 | Val_ACCLoss:  0.1327\n",
      "Fold  11 | Trn_Spearman:  0.0085 | Val_Spearman:  0.1410 | Trn_ACCLoss:  0.1217 | Val_ACCLoss:  0.0627\n",
      "Fold  12 | Trn_Spearman:  0.1279 | Val_Spearman: -0.2005 | Trn_ACCLoss:  0.1279 | Val_ACCLoss:  0.0512\n",
      "Fold  13 | Trn_Spearman: -0.0080 | Val_Spearman: -0.0394 | Trn_ACCLoss:  0.1654 | Val_ACCLoss:  0.2295\n",
      "Fold  14 | Trn_Spearman:  0.0044 | Val_Spearman: -0.0183 | Trn_ACCLoss:  0.1096 | Val_ACCLoss:  0.1147\n",
      "Fold  15 | Trn_Spearman: -0.0535 | Val_Spearman: -0.0632 | Trn_ACCLoss:  0.1473 | Val_ACCLoss:  0.3359\n",
      "Fold  16 | Trn_Spearman:  0.0015 | Val_Spearman:  0.0504 | Trn_ACCLoss:  0.1440 | Val_ACCLoss:  0.0662\n",
      "Fold  17 | Trn_Spearman:  0.0383 | Val_Spearman: -0.1355 | Trn_ACCLoss:  0.1233 | Val_ACCLoss:  0.2517\n",
      "Fold  18 | Trn_Spearman: -0.0073 | Val_Spearman:  0.0110 | Trn_ACCLoss:  0.1703 | Val_ACCLoss:  0.1476\n",
      "Fold  19 | Trn_Spearman:  0.1024 | Val_Spearman: -0.0201 | Trn_ACCLoss:  0.1119 | Val_ACCLoss:  0.0599\n",
      "Fold  20 | Trn_Spearman:  0.0746 | Val_Spearman: -0.1044 | Trn_ACCLoss:  0.1207 | Val_ACCLoss:  0.0937\n",
      "\n",
      "Trn_Spearman:  0.0198 +/-0.0429 | Val_Spearman: -0.0313 +/-0.0823\n",
      "Trn_ACCLoss:   0.1341 +/-0.0178 | Val_ACCLoss:   0.1402 +/-0.0831\n",
      "\n",
      "CPU times: user 46.8 s, sys: 128 ms, total: 46.9 s\n",
      "Wall time: 7.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import lightgbm\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "kfolds = RepeatedKFold(10, n_repeats=2, random_state=42)\n",
    "params = {\n",
    "    'latent_sz': 8,\n",
    "    'learning_rate': 1e-3,\n",
    "    'batch_sz': 16,\n",
    "    'epochs': 20,\n",
    "    'num_negative_samples': 8\n",
    "}\n",
    "results, models = cv_neuralnet(X, y, y_scores, kfolds, params, \n",
    "                               verbose_folds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold   1 | Trn_Spearman:  0.0024 | Val_Spearman: -0.2500 | Trn_ACCLoss:  0.1543 | Val_ACCLoss:  0.2222\n",
      "Fold   2 | Trn_Spearman: -0.0315 | Val_Spearman:  0.0815 | Trn_ACCLoss:  0.1131 | Val_ACCLoss:  0.1618\n",
      "Fold   3 | Trn_Spearman:  0.0130 | Val_Spearman: -0.0247 | Trn_ACCLoss:  0.1500 | Val_ACCLoss:  0.0497\n",
      "Fold   4 | Trn_Spearman:  0.0619 | Val_Spearman:  0.2683 | Trn_ACCLoss:  0.0998 | Val_ACCLoss:  0.1075\n",
      "Fold   5 | Trn_Spearman:  0.0096 | Val_Spearman:  0.0714 | Trn_ACCLoss:  0.1498 | Val_ACCLoss:  0.0450\n",
      "Fold   6 | Trn_Spearman: -0.0506 | Val_Spearman: -0.1767 | Trn_ACCLoss:  0.1598 | Val_ACCLoss:  0.2332\n",
      "Fold   7 | Trn_Spearman:  0.0260 | Val_Spearman:  0.0366 | Trn_ACCLoss:  0.1209 | Val_ACCLoss:  0.1183\n",
      "Fold   8 | Trn_Spearman:  0.0694 | Val_Spearman:  0.2537 | Trn_ACCLoss:  0.1149 | Val_ACCLoss:  0.0140\n",
      "Fold   9 | Trn_Spearman: -0.0380 | Val_Spearman:  0.1429 | Trn_ACCLoss:  0.1254 | Val_ACCLoss:  0.0880\n",
      "Fold  10 | Trn_Spearman:  0.0038 | Val_Spearman: -0.1557 | Trn_ACCLoss:  0.1261 | Val_ACCLoss:  0.2071\n",
      "Fold  11 | Trn_Spearman:  0.0106 | Val_Spearman:  0.1310 | Trn_ACCLoss:  0.1451 | Val_ACCLoss:  0.0475\n",
      "Fold  12 | Trn_Spearman:  0.0073 | Val_Spearman: -0.1401 | Trn_ACCLoss:  0.1457 | Val_ACCLoss:  0.0965\n",
      "Fold  13 | Trn_Spearman: -0.0024 | Val_Spearman:  0.0458 | Trn_ACCLoss:  0.1404 | Val_ACCLoss:  0.1153\n",
      "Fold  14 | Trn_Spearman: -0.0165 | Val_Spearman:  0.1136 | Trn_ACCLoss:  0.1066 | Val_ACCLoss:  0.1133\n",
      "Fold  15 | Trn_Spearman:  0.0050 | Val_Spearman:  0.0971 | Trn_ACCLoss:  0.1172 | Val_ACCLoss:  0.0537\n",
      "Fold  16 | Trn_Spearman:  0.0051 | Val_Spearman:  0.0256 | Trn_ACCLoss:  0.1506 | Val_ACCLoss:  0.1175\n",
      "Fold  17 | Trn_Spearman:  0.0082 | Val_Spearman: -0.1108 | Trn_ACCLoss:  0.1409 | Val_ACCLoss:  0.2240\n",
      "Fold  18 | Trn_Spearman:  0.0324 | Val_Spearman: -0.0714 | Trn_ACCLoss:  0.1311 | Val_ACCLoss:  0.1444\n",
      "Fold  19 | Trn_Spearman:  0.0133 | Val_Spearman:  0.0842 | Trn_ACCLoss:  0.1513 | Val_ACCLoss:  0.0763\n",
      "Fold  20 | Trn_Spearman:  0.0654 | Val_Spearman:  0.0229 | Trn_ACCLoss:  0.1337 | Val_ACCLoss:  0.1192\n",
      "Fold  21 | Trn_Spearman:  0.0329 | Val_Spearman: -0.0119 | Trn_ACCLoss:  0.1704 | Val_ACCLoss:  0.0566\n",
      "Fold  22 | Trn_Spearman: -0.0631 | Val_Spearman: -0.0980 | Trn_ACCLoss:  0.1591 | Val_ACCLoss:  0.2891\n",
      "Fold  23 | Trn_Spearman: -0.0151 | Val_Spearman:  0.0513 | Trn_ACCLoss:  0.1677 | Val_ACCLoss:  0.0581\n",
      "Fold  24 | Trn_Spearman:  0.0153 | Val_Spearman: -0.0321 | Trn_ACCLoss:  0.1048 | Val_ACCLoss:  0.1486\n",
      "Fold  25 | Trn_Spearman:  0.0292 | Val_Spearman:  0.0229 | Trn_ACCLoss:  0.0991 | Val_ACCLoss:  0.0875\n",
      "Fold  26 | Trn_Spearman:  0.0183 | Val_Spearman: -0.0852 | Trn_ACCLoss:  0.1474 | Val_ACCLoss:  0.0674\n",
      "Fold  27 | Trn_Spearman: -0.0100 | Val_Spearman:  0.0778 | Trn_ACCLoss:  0.1466 | Val_ACCLoss:  0.1340\n",
      "Fold  28 | Trn_Spearman:  0.0121 | Val_Spearman: -0.1456 | Trn_ACCLoss:  0.1336 | Val_ACCLoss:  0.1793\n",
      "Fold  29 | Trn_Spearman:  0.0039 | Val_Spearman: -0.1218 | Trn_ACCLoss:  0.1207 | Val_ACCLoss:  0.3157\n",
      "Fold  30 | Trn_Spearman: -0.0274 | Val_Spearman: -0.1758 | Trn_ACCLoss:  0.1618 | Val_ACCLoss:  0.1319\n",
      "Fold  31 | Trn_Spearman: -0.0181 | Val_Spearman: -0.1172 | Trn_ACCLoss:  0.1454 | Val_ACCLoss:  0.0904\n",
      "Fold  32 | Trn_Spearman: -0.0034 | Val_Spearman: -0.1300 | Trn_ACCLoss:  0.1779 | Val_ACCLoss:  0.1242\n",
      "Fold  33 | Trn_Spearman:  0.0058 | Val_Spearman: -0.0568 | Trn_ACCLoss:  0.1679 | Val_ACCLoss:  0.1536\n",
      "Fold  34 | Trn_Spearman: -0.0028 | Val_Spearman: -0.0009 | Trn_ACCLoss:  0.1606 | Val_ACCLoss:  0.1035\n",
      "Fold  35 | Trn_Spearman:  0.0093 | Val_Spearman: -0.0037 | Trn_ACCLoss:  0.1097 | Val_ACCLoss:  0.2120\n",
      "Fold  36 | Trn_Spearman:  0.0234 | Val_Spearman:  0.1456 | Trn_ACCLoss:  0.1149 | Val_ACCLoss:  0.1126\n",
      "Fold  37 | Trn_Spearman:  0.0188 | Val_Spearman: -0.0769 | Trn_ACCLoss:  0.1385 | Val_ACCLoss:  0.0632\n",
      "Fold  38 | Trn_Spearman: -0.0420 | Val_Spearman:  0.1071 | Trn_ACCLoss:  0.1635 | Val_ACCLoss:  0.1071\n",
      "Fold  39 | Trn_Spearman: -0.0439 | Val_Spearman:  0.1007 | Trn_ACCLoss:  0.1514 | Val_ACCLoss:  0.1656\n",
      "Fold  40 | Trn_Spearman:  0.0227 | Val_Spearman: -0.0009 | Trn_ACCLoss:  0.1241 | Val_ACCLoss:  0.0994\n",
      "Fold  41 | Trn_Spearman:  0.0253 | Val_Spearman: -0.1502 | Trn_ACCLoss:  0.1384 | Val_ACCLoss:  0.1209\n",
      "Fold  42 | Trn_Spearman: -0.0189 | Val_Spearman:  0.2033 | Trn_ACCLoss:  0.1380 | Val_ACCLoss:  0.0398\n",
      "Fold  43 | Trn_Spearman:  0.0151 | Val_Spearman:  0.0998 | Trn_ACCLoss:  0.1828 | Val_ACCLoss:  0.1868\n",
      "Fold  44 | Trn_Spearman:  0.0275 | Val_Spearman:  0.0668 | Trn_ACCLoss:  0.0919 | Val_ACCLoss:  0.1387\n",
      "Fold  45 | Trn_Spearman: -0.0893 | Val_Spearman: -0.1035 | Trn_ACCLoss:  0.2170 | Val_ACCLoss:  0.1112\n",
      "Fold  46 | Trn_Spearman: -0.0292 | Val_Spearman: -0.0495 | Trn_ACCLoss:  0.1308 | Val_ACCLoss:  0.1256\n",
      "Fold  47 | Trn_Spearman: -0.0053 | Val_Spearman: -0.2674 | Trn_ACCLoss:  0.1464 | Val_ACCLoss:  0.1183\n",
      "Fold  48 | Trn_Spearman: -0.0410 | Val_Spearman:  0.1090 | Trn_ACCLoss:  0.1954 | Val_ACCLoss:  0.0459\n",
      "Fold  49 | Trn_Spearman:  0.0021 | Val_Spearman: -0.0366 | Trn_ACCLoss:  0.1438 | Val_ACCLoss:  0.2641\n",
      "Fold  50 | Trn_Spearman:  0.0119 | Val_Spearman:  0.1163 | Trn_ACCLoss:  0.1297 | Val_ACCLoss:  0.1540\n",
      "Fold  51 | Trn_Spearman: -0.0520 | Val_Spearman:  0.0733 | Trn_ACCLoss:  0.1479 | Val_ACCLoss:  0.1550\n",
      "Fold  52 | Trn_Spearman: -0.0394 | Val_Spearman:  0.2079 | Trn_ACCLoss:  0.1385 | Val_ACCLoss:  0.0627\n",
      "Fold  53 | Trn_Spearman:  0.0024 | Val_Spearman:  0.0375 | Trn_ACCLoss:  0.1343 | Val_ACCLoss:  0.1038\n",
      "Fold  54 | Trn_Spearman: -0.0158 | Val_Spearman:  0.1905 | Trn_ACCLoss:  0.1268 | Val_ACCLoss:  0.0664\n",
      "Fold  55 | Trn_Spearman: -0.0308 | Val_Spearman:  0.0595 | Trn_ACCLoss:  0.1619 | Val_ACCLoss:  0.1385\n",
      "Fold  56 | Trn_Spearman:  0.0447 | Val_Spearman:  0.2198 | Trn_ACCLoss:  0.1171 | Val_ACCLoss:  0.0741\n",
      "Fold  57 | Trn_Spearman:  0.0236 | Val_Spearman: -0.0568 | Trn_ACCLoss:  0.1256 | Val_ACCLoss:  0.1519\n",
      "Fold  58 | Trn_Spearman: -0.0532 | Val_Spearman:  0.0897 | Trn_ACCLoss:  0.1545 | Val_ACCLoss:  0.0422\n",
      "Fold  59 | Trn_Spearman: -0.0538 | Val_Spearman:  0.1447 | Trn_ACCLoss:  0.1673 | Val_ACCLoss:  0.0835\n",
      "Fold  60 | Trn_Spearman: -0.0561 | Val_Spearman: -0.1529 | Trn_ACCLoss:  0.1631 | Val_ACCLoss:  0.2331\n",
      "Fold  61 | Trn_Spearman: -0.0181 | Val_Spearman:  0.0220 | Trn_ACCLoss:  0.1437 | Val_ACCLoss:  0.1624\n",
      "Fold  62 | Trn_Spearman:  0.0015 | Val_Spearman: -0.1044 | Trn_ACCLoss:  0.1654 | Val_ACCLoss:  0.2619\n",
      "Fold  63 | Trn_Spearman: -0.0732 | Val_Spearman: -0.1419 | Trn_ACCLoss:  0.1588 | Val_ACCLoss:  0.2170\n",
      "Fold  64 | Trn_Spearman: -0.0371 | Val_Spearman:  0.1163 | Trn_ACCLoss:  0.1967 | Val_ACCLoss:  0.0960\n",
      "Fold  65 | Trn_Spearman:  0.0216 | Val_Spearman: -0.0595 | Trn_ACCLoss:  0.1283 | Val_ACCLoss:  0.0962\n",
      "Fold  66 | Trn_Spearman:  0.0011 | Val_Spearman:  0.0082 | Trn_ACCLoss:  0.1152 | Val_ACCLoss:  0.0883\n",
      "Fold  67 | Trn_Spearman:  0.0777 | Val_Spearman: -0.0925 | Trn_ACCLoss:  0.1284 | Val_ACCLoss:  0.1393\n",
      "Fold  68 | Trn_Spearman:  0.0621 | Val_Spearman:  0.1612 | Trn_ACCLoss:  0.1171 | Val_ACCLoss:  0.0857\n",
      "Fold  69 | Trn_Spearman:  0.0017 | Val_Spearman: -0.0394 | Trn_ACCLoss:  0.1428 | Val_ACCLoss:  0.1163\n",
      "Fold  70 | Trn_Spearman:  0.0373 | Val_Spearman: -0.0952 | Trn_ACCLoss:  0.1341 | Val_ACCLoss:  0.1002\n",
      "Fold  71 | Trn_Spearman:  0.0646 | Val_Spearman: -0.0549 | Trn_ACCLoss:  0.1356 | Val_ACCLoss:  0.0557\n",
      "Fold  72 | Trn_Spearman:  0.0246 | Val_Spearman: -0.0339 | Trn_ACCLoss:  0.1299 | Val_ACCLoss:  0.2720\n",
      "Fold  73 | Trn_Spearman:  0.0321 | Val_Spearman: -0.0568 | Trn_ACCLoss:  0.1275 | Val_ACCLoss:  0.0752\n",
      "Fold  74 | Trn_Spearman: -0.0243 | Val_Spearman: -0.1575 | Trn_ACCLoss:  0.1250 | Val_ACCLoss:  0.1398\n",
      "Fold  75 | Trn_Spearman: -0.0744 | Val_Spearman: -0.1218 | Trn_ACCLoss:  0.1512 | Val_ACCLoss:  0.2677\n",
      "Fold  76 | Trn_Spearman: -0.0188 | Val_Spearman:  0.0559 | Trn_ACCLoss:  0.1623 | Val_ACCLoss:  0.0219\n",
      "Fold  77 | Trn_Spearman:  0.0025 | Val_Spearman: -0.0623 | Trn_ACCLoss:  0.1348 | Val_ACCLoss:  0.0503\n",
      "Fold  78 | Trn_Spearman: -0.0163 | Val_Spearman: -0.0339 | Trn_ACCLoss:  0.1765 | Val_ACCLoss:  0.1561\n",
      "Fold  79 | Trn_Spearman:  0.0405 | Val_Spearman: -0.1016 | Trn_ACCLoss:  0.1451 | Val_ACCLoss:  0.0704\n",
      "Fold  80 | Trn_Spearman: -0.0178 | Val_Spearman:  0.0266 | Trn_ACCLoss:  0.1523 | Val_ACCLoss:  0.1048\n",
      "Fold  81 | Trn_Spearman: -0.0144 | Val_Spearman:  0.1410 | Trn_ACCLoss:  0.1688 | Val_ACCLoss:  0.0956\n",
      "Fold  82 | Trn_Spearman:  0.0044 | Val_Spearman: -0.1190 | Trn_ACCLoss:  0.1442 | Val_ACCLoss:  0.0842\n",
      "Fold  83 | Trn_Spearman: -0.0140 | Val_Spearman:  0.2674 | Trn_ACCLoss:  0.1698 | Val_ACCLoss:  0.0813\n",
      "Fold  84 | Trn_Spearman: -0.0780 | Val_Spearman:  0.1383 | Trn_ACCLoss:  0.1312 | Val_ACCLoss:  0.0305\n",
      "Fold  85 | Trn_Spearman: -0.0357 | Val_Spearman:  0.1676 | Trn_ACCLoss:  0.1589 | Val_ACCLoss:  0.1969\n",
      "Fold  86 | Trn_Spearman:  0.0700 | Val_Spearman:  0.0366 | Trn_ACCLoss:  0.1538 | Val_ACCLoss:  0.0865\n",
      "Fold  87 | Trn_Spearman: -0.0190 | Val_Spearman: -0.1529 | Trn_ACCLoss:  0.1184 | Val_ACCLoss:  0.2988\n",
      "Fold  88 | Trn_Spearman:  0.0591 | Val_Spearman: -0.1016 | Trn_ACCLoss:  0.1093 | Val_ACCLoss:  0.2210\n",
      "Fold  89 | Trn_Spearman:  0.0311 | Val_Spearman:  0.1511 | Trn_ACCLoss:  0.1512 | Val_ACCLoss:  0.0627\n",
      "Fold  90 | Trn_Spearman: -0.0081 | Val_Spearman: -0.0293 | Trn_ACCLoss:  0.1519 | Val_ACCLoss:  0.1552\n",
      "Fold  91 | Trn_Spearman:  0.0116 | Val_Spearman:  0.0751 | Trn_ACCLoss:  0.1372 | Val_ACCLoss:  0.2699\n",
      "Fold  92 | Trn_Spearman:  0.0404 | Val_Spearman: -0.0458 | Trn_ACCLoss:  0.1467 | Val_ACCLoss:  0.1624\n",
      "Fold  93 | Trn_Spearman:  0.0250 | Val_Spearman:  0.0733 | Trn_ACCLoss:  0.1500 | Val_ACCLoss:  0.0312\n",
      "Fold  94 | Trn_Spearman: -0.0051 | Val_Spearman: -0.1786 | Trn_ACCLoss:  0.1232 | Val_ACCLoss:  0.2115\n",
      "Fold  95 | Trn_Spearman: -0.0315 | Val_Spearman:  0.0174 | Trn_ACCLoss:  0.1387 | Val_ACCLoss:  0.1605\n",
      "Fold  96 | Trn_Spearman:  0.0156 | Val_Spearman:  0.1026 | Trn_ACCLoss:  0.1371 | Val_ACCLoss:  0.1309\n",
      "Fold  97 | Trn_Spearman:  0.0411 | Val_Spearman:  0.1593 | Trn_ACCLoss:  0.1202 | Val_ACCLoss:  0.1110\n",
      "Fold  98 | Trn_Spearman: -0.0228 | Val_Spearman: -0.1282 | Trn_ACCLoss:  0.1480 | Val_ACCLoss:  0.1645\n",
      "Fold  99 | Trn_Spearman:  0.0820 | Val_Spearman: -0.0339 | Trn_ACCLoss:  0.1568 | Val_ACCLoss:  0.1571\n",
      "Fold 100 | Trn_Spearman:  0.0850 | Val_Spearman:  0.0385 | Trn_ACCLoss:  0.1230 | Val_ACCLoss:  0.0930\n",
      "\n",
      "Trn_Spearman:  0.0015 +/-0.0366 | Val_Spearman:  0.0051 +/-0.1185\n",
      "Trn_ACCLoss:   0.1420 +/-0.0218 | Val_ACCLoss:   0.1285 +/-0.0677\n",
      "\n",
      "CPU times: user 14min 25s, sys: 2.76 s, total: 14min 28s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import lightgbm\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "kfolds = RepeatedKFold(10, n_repeats=10, random_state=42)\n",
    "params = {\n",
    "    'latent_sz': 8,\n",
    "    'learning_rate': 1e-2,\n",
    "    'batch_sz': 16,\n",
    "    'epochs': 100\n",
    "}\n",
    "results, models = cv_neuralnet(X, y, y_scores, kfolds, params, \n",
    "                               verbose_folds=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = RankDataset(X, y, y_scores)\n",
    "dl = DataLoader(ds, batch_size=params['batch_sz'], shuffle=False)\n",
    "y_pred = models[0].predict(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 13), (60, 13), (60, 13))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape, y.shape, y_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15265806292078446"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metric('mean_acc_loss', y_scores, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  2,  1,  8, 12,  6,  4,  9,  7, 13, 10, 11,  3])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11,  5,  4, 12,  7,  8, 13,  9, 10,  3,  2,  1,  6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 13,  6, 10,  5,  1,  3,  4,  9,  7, 11,  2,  8])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  4, 12,  5,  1, 13,  8,  3, 11,  7,  6, 10,  9])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
