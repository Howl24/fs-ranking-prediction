{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import os\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt, seaborn as sns\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from pathlib import Path\n",
    "# pd.set_option('display.max_columns', 1000)\n",
    "# pd.set_option('display.max_rows', 400)\n",
    "sns.set()\n",
    "\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from project.ranker.ranker import RankingPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 39) (60, 13) (60, 13)\n",
      "CPU times: user 1min 9s, sys: 5.95 s, total: 1min 15s\n",
      "Wall time: 1min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import train_test_split\n",
    "rp = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('estimator', RankingPredictor(\"ma_100\", n_neighbors=15)),\n",
    "])\n",
    "df_mf, df_rank, df_scores = rp.named_steps['estimator'].get_data()\n",
    "\n",
    "X, _, y, _, y_scores, _ = train_test_split(df_mf.values,\n",
    "                                           df_rank.values,\n",
    "                                           df_scores.values,\n",
    "                                           test_size=0,\n",
    "                                           random_state=42)\n",
    "print(X.shape, y.shape, y_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "class RankDataset(Dataset):\n",
    "    def __init__(self, X, y, y_scores):\n",
    "        super().__init__()\n",
    "        self.X = X.astype(np.float32)\n",
    "        self.y = y.astype(np.int64)\n",
    "        self.y_scores = y_scores.astype(np.float32)\n",
    "        \n",
    "        self.mf_sz = X.shape[1]\n",
    "        self.fs_sz = y.shape[1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return [self.X[idx], self.y[idx], self.y_scores[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wide2long(X, y):\n",
    "    n_samples, n_classes = y.shape\n",
    "    X_cont = np.repeat(X, n_classes, axis=0)\n",
    "    X_cats = np.array(list(range(n_classes)) * n_samples)\n",
    "    return X_cont, X_cats.astype(int), y.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from project.ranker.neural_ranker import RankNet\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "class NeuralNetwork():\n",
    "    def __init__(self, mf_sz, fs_sz, params):\n",
    "        self.mf_sz, self.fs_sz = mf_sz, fs_sz\n",
    "        self.latent_sz = params['latent_sz']\n",
    "        self.epochs = params['epochs']\n",
    "        self.lr = params['learning_rate']\n",
    "        \n",
    "        self.model = RankNet(mf_sz, fs_sz, self.latent_sz)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "    def train(self, dl):\n",
    "        \n",
    "        \n",
    "        pass\n",
    "        \n",
    "    def predict(self, dl):\n",
    "        preds = []\n",
    "        self.model.eval()\n",
    "        for X, y, y_scores in dl:\n",
    "            X_cont, X_cats, y_long = wide2long(X, y)\n",
    "            X_cats = torch.LongTensor(X_cats)\n",
    "            X_cont.requires_grad_(False)\n",
    "            X_cats.requires_grad_(False)\n",
    "            \n",
    "            pred = self.model(X_cont, X_cats).cpu().detach().numpy()\n",
    "            \n",
    "            pred = np.array([rankdata(x, method='ordinal') for x in \\\n",
    "                             np.reshape(pred, y.shape)]).astype(int)\n",
    "            preds.extend(pred)\n",
    "        return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from project.utils.metrics import evaluate_metric\n",
    "\n",
    "def cv_neuralnet(X, y, y_scores, kfolds, params, verbose_folds=False):\n",
    "    results = []\n",
    "    models = []\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    for idx, (trn_idx, val_idx) in enumerate(kfolds.split(X, y)):\n",
    "        X_trn, y_trn, y_scores_trn = X[trn_idx], y[trn_idx], y_scores[trn_idx]\n",
    "        X_val, y_val, y_scores_val = X[val_idx], y[val_idx], y_scores[val_idx]\n",
    "        \n",
    "        trn_ds = RankerDataset(X_trn, y_trn, y_scores_trn)\n",
    "        val_ds = RankerDataset(X_val, y_val, y_scores_val)\n",
    "        \n",
    "        neuralnet = NeuralNetwork(trn_ds.mf_sz, trn_ds.fs_sz, params)\n",
    "        trn_dl = DataLoader(trn_ds, batch_size=params['batch_sz'], shuffle=True)\n",
    "        neuralnet.train(trn_dl)\n",
    "        \n",
    "        trn_dl = DataLoader(trn_ds, batch_size=params['batch_sz'], shuffle=False)\n",
    "        val_dl = DataLoader(val_ds, batch_size=params['batch_sz'], shuffle=False)\n",
    "        \n",
    "        y_pred_trn = neuralnet.predict(trn_dl)\n",
    "        y_pred_val = neuralnet.predict(val_dl)\n",
    "        \n",
    "        trn_spearman = evaluate_metric(\"spearman\", y_trn, y_pred_trn)\n",
    "        trn_acc_loss = evaluate_metric(\"mean_acc_loss\", y_scores_trn, y_pred_trn)\n",
    "        val_spearman = evaluate_metric(\"spearman\", y_val, y_pred_val)\n",
    "        val_acc_loss = evaluate_metric(\"mean_acc_loss\", y_scores_val, y_pred_val)\n",
    "        \n",
    "        if verbose_folds:\n",
    "            print(f'Fold {idx + 1:>3} | '\n",
    "                  f'Trn_Spearman: {trn_spearman: .4f} | '\n",
    "                  f'Val_Spearman: {val_spearman: .4f} | '\n",
    "                  f'Trn_ACCLoss: {trn_acc_loss: .4f} | '\n",
    "                  f'Val_ACCLoss: {val_acc_loss: .4f}')\n",
    "            \n",
    "        results.append((trn_spearman, val_spearman, \n",
    "                        trn_acc_loss, val_acc_loss))\n",
    "        models.append(neuralnet)\n",
    "          \n",
    "    results = np.array(results)\n",
    "    print()\n",
    "    print(f'Trn_Spearman: {results[:,0].mean(): .4f} +/-{results[:,0].std():.4f} | '\n",
    "          f'Val_Spearman: {results[:,1].mean(): .4f} +/-{results[:,1].std():.4f}\\n'\n",
    "          f'Trn_ACCLoss:  {results[:,2].mean(): .4f} +/-{results[:,2].std():.4f} | '\n",
    "          f'Val_ACCLoss:  {results[:,3].mean(): .4f} +/-{results[:,3].std():.4f}')\n",
    "    print()\n",
    "    return results, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trn_Spearman:  0.0060 +/-0.0506 | Val_Spearman:  0.0016 +/-0.1074\n",
      "Trn_ACCLoss:   0.1373 +/-0.0206 | Val_ACCLoss:   0.1471 +/-0.0664\n",
      "\n",
      "CPU times: user 19.2 s, sys: 76 ms, total: 19.3 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import lightgbm\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "kfolds = RepeatedKFold(10, n_repeats=10, random_state=42)\n",
    "params = {\n",
    "    'latent_sz': 6,\n",
    "    'learning_rate': 3e-4,\n",
    "    'batch_sz': 16,\n",
    "    'epochs': 20\n",
    "}\n",
    "results, models = cv_neuralnet(X, y, y_scores, kfolds, params, \n",
    "                               verbose_folds=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = RankerDataset(X, y, y_scores)\n",
    "dl = DataLoader(ds, batch_size=params['batch_sz'], shuffle=False)\n",
    "y_pred = models[10].predict(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60, 13), (60, 13), (60, 13))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape, y.shape, y_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12113399553008085"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_metric('mean_acc_loss', y_scores, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
